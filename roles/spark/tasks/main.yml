---
- name: update packages
  package: name=* state=latest

- name: install dependencies
  package: name={{ item }} state=latest
  with_items:
    - unzip
    - libselinux-python
    - zlib-devel
    - openssl-devel
    - perl-ExtUtils-MakeMaker
    - gcc
    - readline
    - readline-devel
    - lapack-devel
    - freetype
    - freetype-devel
    - libpng-devel
    - python-devel
    - python-setuptools
    - ncurses-devel
    - patch

- name: install java
  package: name=java-{{ java_version.redhat }}-openjdk state=latest
  when: ansible_os_family == "RedHat"

- name: install java
  package: name=openjdk-{{ java_version.debian }}-jre state=latest
  when: ansible_os_family == "Debian"

- name: install hadoop
  unarchive:
    src: http://ftp.jaist.ac.jp/pub/apache/hadoop/common/hadoop-2.7.3/hadoop-2.7.3.tar.gz
    dest: /usr/local/src
    owner: "{{ user }}"
    group: "{{ user }}"
    remote_src: True

- name: set hadoop conf
  copy:
    src: "{{ item }}"
    dest: /usr/local/src/hadoop-2.7.3/etc/hadoop
    mode: 0644
  with_items:
    - core-site.xml
    - hdfs-site.xml
    - yarn-site.xml

- name: dest mysql rpm
  copy:
    src: mysql57-community-release-el7-11.noarch.rpm
    dest: /usr/local/lib

- name: rpm install mysql
  package: name=/usr/local/lib/mysql57-community-release-el7-11.noarch.rpm state=present

- name: enable mysql57
  shell: yum-config-manager --enable mysql57-community

- name: dest mysql jdbc driver
  unarchive:
    src: mysql-connector-java-5.1.42.tar.gz
    dest: /usr/local/lib

- name: install mysql
  package: name={{ item }} state=latest
  with_items:
    - mysql-community-server
    - mysql-community-devel
    - mysql-community-client
    - mysql-community-libs

- name: install spark
  unarchive:
    src: https://d3kbcqa49mib13.cloudfront.net/{{ spark_relase_name }}.tgz
    dest: /usr/local/src
    remote_src: True
    owner: "{{ user }}"
    group: "{{ user }}"

- name: unarchive python
  unarchive:
    src: https://www.python.org/ftp/python/{{ python_version }}/Python-{{ python_version }}.tgz
    dest: /usr/local/src
    remote_src: True
    owner: "{{ user }}"
    group: "{{ user }}"

- name: install python
  shell: ./configure && make && make install
  args:
    chdir: /usr/local/src/Python-{{ python_version }}

- name: install pip
  shell: curl -kL https://bootstrap.pypa.io/get-pip.py | python
  become: False

- name: install python mlib dependencies
  pip: name={{ item }} extra_args="--user"
  with_items:
    - numpy
    - pandas
    - matplotlib
    - readline
  become: False

- name: unarchive scala
  unarchive:
    src: https://downloads.lightbend.com/scala/{{ scala_version }}/scala-{{ scala_version }}.tgz
    dest: /usr/local/src
    remote_src: True
    owner: "{{ user }}"
    group: "{{ user }}"

- name: install sbt rpm
  shell: curl https://bintray.com/sbt/rpm/rpm | sudo tee /etc/yum.repos.d/bintray-sbt-rpm.repo

- name: install sbt
  package: name=sbt state=latest

- name: setting env
  copy:
    src: spark-env.sh
    dest: /etc/profile.d/spark-env.sh
    mode: 0644
    owner: root
    group: root

- name: dest config xml
  copy:
    src: gcs-core-default.xml
    dest: /usr/local/src/{{ spark_relase_name }}/conf/gcs-core.xml
    mode: 0644
    owner: "{{ user }}"
    group: "{{ user }}"

# - name: start hadoop
#   shell: "{{ item }}"
#   with_items:
#     - export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.131-3.b12.el7_3.x86_64/jre && /usr/local/src/hadoop-2.7.3/sbin/stop-all.sh
#     - export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.131-3.b12.el7_3.x86_64/jre && /usr/local/src/hadoop-2.7.3/sbin/start-all.sh

- name: start spark
  shell: "{{ item }}"
  with_items:
    - /usr/local/src/{{ spark_relase_name }}/sbin/stop-master.sh
    - /usr/local/src/{{ spark_relase_name }}/sbin/start-master.sh

- name: create spark-training directory
  shell: mkdir -p /home/{{ user }}/spark-training
  become: False

- name: dest training data
  unarchive:
    src: training.zip
    dest: /home/{{ user }}/spark-training
    owner: "{{ user }}"
    group: "{{ user }}"
  become: False
